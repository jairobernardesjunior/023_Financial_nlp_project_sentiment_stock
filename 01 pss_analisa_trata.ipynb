{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project sentiment stock\n",
    "\n",
    "### Objective:\n",
    "- In this project, we will perform a sentiment analysis of data published on X (Twitter), in real time, relating to stock market quotes. This analysis can be passed on to our investors, through sentiment percentages, whether the messages about the quotes present a positive or negative trend for the subject in question.\n",
    "\n",
    "- Nesse projeto vamos fazer uma análise de sentimento de dados publicados no X (twitter), em tempo real, relativo às cotações da bolsa de valores. Essa análise vai poder passar para nossos investidores, através dos percentuais de sentimento, se as postagens sobre as cotações, apresentam uma tendência positiva ou negativa para o assunto tratado.\n",
    "\n",
    "### Data Origin:\n",
    "- Dataset: financial_tweets.csv\n",
    "\n",
    "- This file was acquired by capturing tweets from users who made publications within the subject discussed here, expressing their feelings about stock market quotes in real time. The data is intercepted through an API provided by X (twitter) and saved in a .csv file.\n",
    "\n",
    "- Esse arquivo foi adquirido através da captura de tweets dos usuários que fizeram publicações dentro do assunto aqui tratado, expressando seus sentimentos sobre cotações da bolsa em tempo real. Os dados são interceptados através de API fornecida pelo X (twitter) e gravados em arquivo .csv.\n",
    "\n",
    "Aqui o que nos interessa é somente o campo:\n",
    "- Description: descrição do sentimento publicado pelo usuário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Análise exploratória dos dados\n",
    "- ## Preparação dos dados\n",
    "- ## Armazenamento dos dados tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximiza nro de linhas e colunas para exibição\n",
    "# inibe mensagens de warning\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None) # permite a máxima visualização das linhas em um display\n",
    "pd.set_option('display.max_columns', None) # permite a máxima visualização das colunas em um display\n",
    "import warnings\n",
    "warnings.simplefilter('ignore') # inibe a exibição de avisos de warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\KR\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# bibliotecas\n",
    "import tweepy as tw\n",
    "import numpy as np # computação de matrizes\n",
    "\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'bokA1eIxmcK5y396klmyThyxE'\n",
    "consumer_secret = 'kpI1wT4So74kl6OVbv10rMUk5xkPNJZhkCCPScf5cyzHjLCJ62'\n",
    "access_token = '2689849668-kaDvfg15xpeF4a1D6pL9ck1EnYTQhBjGklcS77S'\n",
    "access_token_secret = 'zPdg70A5cnkmmXmuvM62TlkxoHl4IHJGpGfD3c5stfday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "autorizacao = tw.OAuthHandler(consumer_key, consumer_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "autorizacao.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tw.API(autorizacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meus_tweets = api.home_timeline() # retorna uma coleção dos Tweets e Retweets mais recentes postados pelo usuário autenticado e pelos usuários que ele segue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for twitters in meus_tweets:\n",
    "    print(twitters.created_at)\n",
    "    print(twitters.text,  '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"bitcoin AND price\"\n",
    "pesquisa = api.search(q=query,lang='en',tweet_mode=\"extended\",count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = []\n",
    "\n",
    "for twitters in pesquisa:\n",
    "  resultado.append(twitters.created_at)\n",
    "  resultado.append(twitters.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_np = np.array(resultado)\n",
    "matriz_ajustada = np.reshape(matriz_np, (50,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "colunas = [\n",
    "    'Data_publicacao',\n",
    "    'tweet'\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(matriz_ajustada,columns=colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_tweets = 'dataset/financial_tweets.csv'\n",
    "df.to_csv(arquivo_tweets, encoding='utf-8', index=False,quotechar='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando arquivo tratado em dataframe\n",
    "df_sentiment = pd.read_csv('dataset/financial_tweets.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sentiment['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Crazy that $PRIME is going to >$1B market cap ...\n",
       "1    Crazy part is, a lot of what I have been tradi...\n",
       "2                       $AVAX\\n\\nStacking on support..\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words(\"english\")\n",
    "\n",
    "punctuation_words = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = df.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = []\n",
    "\n",
    "for tweet in tweet_list:\n",
    "    \n",
    "    tweet = str(tweet) \n",
    "\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    tweet = re.sub(r'$', '', tweet)\n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "    tweet = re.sub(r'https?://[A-Za-z0-9./]+','',tweet)\n",
    "    tweet = re.sub(r'https//[A-Za-z0-9./]+','',tweet)\n",
    "    tweet = tweet.replace(\"\\n\",\"\")\n",
    "    tweet = re.sub('@[\\w]+', '', tweet)\n",
    "\n",
    "    tweet = re.sub(r\"n't\", \" not \", tweet)\n",
    "    tweet = re.sub(r\"\\'s\", \" \", tweet)\n",
    "    tweet = re.sub(r\"\\'ve\", \" have \", tweet)\n",
    "    tweet = re.sub(r\"\\'re\", \" are \", tweet)\n",
    "    tweet = re.sub(r\"\\'d\", \" would \", tweet)\n",
    "    tweet = re.sub(r\"\\'ll\", \" will \", tweet) \n",
    "\n",
    "    tweet = tweet.lower()\n",
    "    tweet = tweet.strip()\n",
    "\n",
    "    clean_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crazy that  is going to > market cap at the next cycle top as the “  of this cycle” and you still don’t own any anon. -100 exit or bust bitch.',\n",
       " 'crazy part is, a lot of what i have been trading is still up..',\n",
       " 'stacking on support..',\n",
       " 'lfg!!']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(clean_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crazy that  is going to &gt; market cap at the ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crazy part is, a lot of what i have been tradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stacking on support..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lfg!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- twitter been super bullish on this one and t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  crazy that  is going to > market cap at the ne...\n",
       "1  crazy part is, a lot of what i have been tradi...\n",
       "2                              stacking on support..\n",
       "3                                              lfg!!\n",
       "4  - twitter been super bullish on this one and t..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tblob = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vader = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_tblob.itertuples():\n",
    "    tweet = df_tblob.at[row[0],0]\n",
    "    analysis = TextBlob(tweet)\n",
    "    df_tblob.at[row[0], 'polarity'] = analysis.sentiment[0]\n",
    "    df_tblob.at[row[0], 'subjectivity'] = analysis.sentiment[1]\n",
    "    if analysis.sentiment[0]>0:\n",
    "        df_tblob.at[row[0], 'Sentiment'] = \"Positive\"\n",
    "    elif analysis.sentiment[0]<0:\n",
    "        df_tblob.at[row[0], 'Sentiment'] = \"Negative\"\n",
    "    else:\n",
    "        df_tblob.at[row[0], 'Sentiment'] = \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crazy that  is going to &gt; market cap at the ne...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crazy part is, a lot of what i have been tradi...</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.900</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stacking on support..</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lfg!!</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- twitter been super bullish on this one and t...</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>0.325</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  polarity  subjectivity  \\\n",
       "0  crazy that  is going to > market cap at the ne...  0.125000         0.600   \n",
       "1  crazy part is, a lot of what i have been tradi... -0.600000         0.900   \n",
       "2                              stacking on support..  0.000000         0.000   \n",
       "3                                              lfg!!  0.000000         0.000   \n",
       "4  - twitter been super bullish on this one and t...  0.195833         0.325   \n",
       "\n",
       "  Sentiment  \n",
       "0  Positive  \n",
       "1  Negative  \n",
       "2   Neutral  \n",
       "3   Neutral  \n",
       "4  Positive  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tblob.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df_vader[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 2\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mSentimentIntensityAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpolarity_scores(row)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m score[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpos\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      4\u001b[0m         df_vader\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\KR\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\sentiment\\vader.py:341\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.__init__\u001b[1;34m(self, lexicon_file)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    338\u001b[0m     lexicon_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    339\u001b[0m ):\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexicon_file \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mload(lexicon_file)\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexicon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_lex_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstants \u001b[38;5;241m=\u001b[39m VaderConstants()\n",
      "File \u001b[1;32mc:\\Users\\KR\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\sentiment\\vader.py:351\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.make_lex_dict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexicon_file\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    350\u001b[0m     (word, measure) \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m--> 351\u001b[0m     lex_dict[word] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(measure)\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lex_dict\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for index, row in df_vader[0].items():\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    if score['neg'] > score['pos']:\n",
    "        df_vader.loc[index, \"Sentiment\"] = \"Negative\"\n",
    "    elif score['pos'] > score['neg']:\n",
    "        df_vader.loc[index, \"Sentiment\"] = \"Positive\"\n",
    "    else:\n",
    "        df_vader.loc[index, \"Sentiment\"] = \"Neutral\"\n",
    "        \n",
    "    df_vader.loc[index, 'neg'] = score['neg']\n",
    "    df_vader.loc[index, 'neu'] = score['neu']\n",
    "    df_vader.loc[index, 'pos'] = score['pos']\n",
    "    df_vader.loc[index, 'compound'] = score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vader.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(review):\n",
    "    tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert[0] = df_bert[0].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row  in df_bert[0].iteritems():\n",
    "    score = sentiment_score(row)\n",
    "    if score > 3:\n",
    "        df_bert.loc[index, \"Sentiment\"] = \"Positive\"\n",
    "    elif score < 3:\n",
    "        df_bert.loc[index, \"Sentiment\"] = \"Negative\"\n",
    "    else:\n",
    "        df_bert.loc[index, \"Sentiment\"] = \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
